{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "576e720a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu118\n",
      "True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40532365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training files: {'562_Mixed4_processed.csv', '571_Mixed4_processed.csv', '551_LA92_processed.csv', '556_US06_processed.csv', '567_Mixed1_processed.csv', '576_UDDS_processed.csv', '551_UDDS_processed.csv', '604_Mixed3_processed.csv', '611_Mixed8_processed.csv', '596_LA92_processed.csv', '590_Mixed4_processed.csv', '551_US06_processed.csv', '571_Mixed5_processed.csv', '556_Mixed2_processed.csv', '589_LA92_processed.csv', '604_Mixed6_processed.csv', '562_Mixed7_processed.csv', '590_PausCycl_processed.csv', '557_Cap_1C_processed.csv', '562_Mixed8_processed.csv', '610_Cap_1C_processed.csv', '552_Cap_1C_processed.csv', '589_Mixed2_processed.csv', '589_Cap_1C_processed.csv', '551_Mixed2_processed.csv', '590_Mixed5_processed.csv', '571_Mixed7_processed.csv', '571_Mixed6_processed.csv', '590_Mixed6_processed.csv', '552_Mixed5_processed.csv', '552_Mixed8_processed.csv', '596_UDDS_processed.csv', '604_PausCycl_processed.csv', '610_Mixed1_processed.csv', '610_US06_processed.csv', '571_PausCycl_processed.csv', '590_Mixed7_processed.csv', '567_Mixed2_processed.csv', '611_Mixed5_processed.csv', '562_Mixed5_processed.csv', '571_Cap_1C_processed.csv', '585_HPPC_processed.csv', '567_US06_processed.csv', '611_PausCycl_processed.csv', '589_Mixed1_processed.csv', '604_Mixed7_processed.csv', '611_Mixed7_processed.csv', '551_Cap_1C_processed.csv', '601_Mixed1_processed.csv', '607_HPPC_processed.csv', '556_Mixed1_processed.csv', '589_UDDS_processed.csv', '596_HWFET_processed.csv', '551_Mixed1_processed.csv', '601_US06_processed.csv', '611_Cap_1C_processed.csv', '576_HWFET_processed.csv', '552_PausCycl_processed.csv', '552_Mixed4_processed.csv', '590_Mixed8_processed.csv', '556_UDDS_processed.csv', '611_Mixed3_processed.csv', '610_UDDS_processed.csv', '611_Mixed4_processed.csv', '611_Mixed6_processed.csv', '589_HWFET_processed.csv', '562_Mixed6_processed.csv', '575_HPPC_processed.csv', '556_HWFET_processed.csv', '549_HPPC_processed.csv', '589_US06_processed.csv', '596_Cap_1C_processed.csv'}\n",
      "\n",
      "Validation files: {'602_Cap_1C_processed.csv', '610_HWFET_processed.csv', '552_Mixed3_processed.csv', '552_Mixed7_processed.csv', '552_Mixed6_processed.csv', '556_LA92_processed.csv', '601_Mixed2_processed.csv', '562_PausCycl_processed.csv', '557_Mixed3_processed.csv'}\n",
      "\n",
      "Testing files: {'602_Mixed5_processed.csv', '610_LA92_processed.csv', '610_Mixed2_processed.csv', '593_HPPC_processed.csv', '555_HPPC_processed.csv', '571_Mixed8_processed.csv', '602_Mixed4_processed.csv', '604_Mixed8_processed.csv', '576_Cap_1C_processed.csv'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna\n",
    "from torch.profiler import profile, ProfilerActivity\n",
    "import time \n",
    "from torch.cuda.amp import GradScaler, autocast \n",
    "\n",
    "# Check if the environment variable is set to 'True'\n",
    "skip_training = os.getenv('SKIP_TRAINING', 'False') == 'True'\n",
    "skip_optuna = os.getenv('SKIP_OPTUNA', 'False') == 'True'\n",
    "\n",
    "PROCESSED_DATA_DIR = '../dataset/LG_HG2_processed'\n",
    "FEATURE_COLS = ['Voltage [V]', 'Current [A]', 'Temperature [degC]', 'Power [W]', 'CC_Capacity [Ah]']\n",
    "LABEL_COL = 'SOC [-]'\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0001\n",
    "SEQUENCE_LENGTH = 20  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Function to load data\n",
    "def load_data(directory, temperatures):\n",
    "    frames = []    \n",
    "    for temp_folder in os.listdir(directory):\n",
    "        if temp_folder in temperatures:\n",
    "            temp_path = os.path.join(directory, temp_folder)\n",
    "            for file in os.listdir(temp_path):\n",
    "                if 'Charge' in file or 'Dis' in file:\n",
    "                    continue  # Skip constant charge and discharge files\n",
    "                if file.endswith('.csv'):\n",
    "                    df = pd.read_csv(os.path.join(temp_path, file))\n",
    "                    df['SourceFile'] = file\n",
    "\n",
    "                    # Calculate power\n",
    "                    df['Power [W]'] = df['Voltage [V]'] * df['Current [A]']\n",
    "\n",
    "                    # Initialize CC_Capacity [Ah] column\n",
    "                    df['CC_Capacity [Ah]'] = 0.0\n",
    "\n",
    "                    # Integrating current over time to calculate cumulative capacity\n",
    "                    df['CC_Capacity [Ah]'] = (df['Current [A]'] * df['Time [s]'].diff().fillna(0) / 3600).cumsum()\n",
    "\n",
    "                    frames.append(df)\n",
    "    return pd.concat(frames, ignore_index=True)\n",
    "\n",
    "\n",
    "# Custom dataset class for LSTM\n",
    "class BatteryDatasetLSTM(Dataset):\n",
    "    def __init__(self, data_tensor, labels_tensor, sequence_length=50, filenames=None, times=None):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.features = data_tensor\n",
    "        self.labels = labels_tensor\n",
    "        self.filenames = filenames \n",
    "        self.times = times \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx_end = idx + self.sequence_length\n",
    "        sequence = self.features[idx:idx_end]\n",
    "        label = self.labels[idx_end - 1]\n",
    "        filename = self.filenames[idx_end - 1]\n",
    "        time = self.times[idx_end - 1]  \n",
    "\n",
    "        sequence = sequence.clone().detach()\n",
    "        label = label.clone().detach()\n",
    "\n",
    "        return sequence, label, filename, time\n",
    "    \n",
    "    def get_unique_filenames(self):\n",
    "        return set(self.filenames)\n",
    "    \n",
    "    def get_times(self):\n",
    "        return self.times\n",
    "\n",
    "# SoCLSTM Model\n",
    "class SoCLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(SoCLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, dtype=x.dtype, device=x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, dtype=x.dtype, device=x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Training loop with validation\n",
    "def train_and_validate(model, criterion, optimizer, train_loader, val_loader, epochs, device, patience=20, min_delta=0.001):\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        total_iterations = len(train_loader)\n",
    "        epoch_start_time = time.time()\n",
    "        for sequences, labels, _, _ in train_loader:  \n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            labels = labels.unsqueeze(1) \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        epoch_end_time = time.time()\n",
    "        epoch_time = epoch_end_time - epoch_start_time\n",
    "        train_loss /= len(train_loader)\n",
    "        history['train_loss'].append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels, _, _ in val_loader:  \n",
    "                sequences, labels = sequences.to(device), labels.to(device)\n",
    "                labels = labels.unsqueeze(1)  \n",
    "                outputs = model(sequences)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        history['val_loss'].append(val_loss)\n",
    "\n",
    "        # Early stopping logic\n",
    "        if val_loss < best_val_loss - min_delta:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss}, Validation Loss: {val_loss}')\n",
    "        print(f'Time taken for epoch: {epoch_time:.8f} seconds')\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print('Early stopping triggered')\n",
    "            # break\n",
    "\n",
    "    return history\n",
    "\n",
    "temperatures_to_process = ['25degC', '0degC', 'n10degC', 'n20degC', '10degC', '40degC']   \n",
    "# temperatures_to_process = ['25degC', '0degC', '10degC'] \n",
    "data = load_data(PROCESSED_DATA_DIR, temperatures_to_process)\n",
    "# Apply a moving average filter to your features\n",
    "#window_size = 5 \n",
    "#smoothed_data = data[FEATURE_COLS].rolling(window=window_size, min_periods=1).mean()\n",
    "# Replace the original features with the smoothed features\n",
    "#data[FEATURE_COLS] = smoothed_data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data[FEATURE_COLS] = scaler.fit_transform(data[FEATURE_COLS])\n",
    "\n",
    "unique_files = np.array(list(set(data['SourceFile'])))\n",
    "\n",
    "# Convert to tensors and load into GPU memory\n",
    "data_tensor = torch.tensor(data[FEATURE_COLS].values, dtype=torch.float32).to(device)\n",
    "\n",
    "labels_tensor = torch.tensor(data[LABEL_COL].values, dtype=torch.float32).to(device)\n",
    "\n",
    "filenames_tensor = data['SourceFile'].values\n",
    "unique_filelabels_tensors = np.array(list(set(data['SourceFile'])))\n",
    "train_files, temp_files = train_test_split(unique_files, test_size=0.2, random_state=24)\n",
    "val_files, test_files = train_test_split(temp_files, test_size=0.5, random_state=24)\n",
    "\n",
    "def filter_data_by_filenames(df, filenames):\n",
    "    return df[df['SourceFile'].isin(filenames)]\n",
    "\n",
    "# Filter data for each set\n",
    "train_data = filter_data_by_filenames(data, train_files)\n",
    "val_data = filter_data_by_filenames(data, val_files)\n",
    "test_data = filter_data_by_filenames(data, test_files)\n",
    "\n",
    "# Convert to tensors\n",
    "train_tensor = torch.tensor(train_data[FEATURE_COLS].values, dtype=torch.float32).to(device)\n",
    "train_labels = torch.tensor(train_data[LABEL_COL].values, dtype=torch.float32).to(device)\n",
    "\n",
    "val_tensor = torch.tensor(val_data[FEATURE_COLS].values, dtype=torch.float32).to(device)\n",
    "val_labels = torch.tensor(val_data[LABEL_COL].values, dtype=torch.float32).to(device)\n",
    "\n",
    "test_tensor = torch.tensor(test_data[FEATURE_COLS].values, dtype=torch.float32).to(device)\n",
    "test_labels = torch.tensor(test_data[LABEL_COL].values, dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "# Convert filtered data to tensors and create dataset instances\n",
    "train_dataset = BatteryDatasetLSTM(\n",
    "    torch.tensor(train_data[FEATURE_COLS].values, dtype=torch.float32).to(device),\n",
    "    torch.tensor(train_data[LABEL_COL].values, dtype=torch.float32).to(device),\n",
    "    SEQUENCE_LENGTH,\n",
    "    train_data['SourceFile'].values,\n",
    "    train_data['Time [s]'].values  \n",
    ")\n",
    "\n",
    "val_dataset = BatteryDatasetLSTM(\n",
    "    torch.tensor(val_data[FEATURE_COLS].values, dtype=torch.float32).to(device),\n",
    "    torch.tensor(val_data[LABEL_COL].values, dtype=torch.float32).to(device),\n",
    "    SEQUENCE_LENGTH,\n",
    "    val_data['SourceFile'].values,\n",
    "    val_data['Time [s]'].values  \n",
    ")\n",
    "\n",
    "test_dataset = BatteryDatasetLSTM(\n",
    "    torch.tensor(test_data[FEATURE_COLS].values, dtype=torch.float32).to(device),\n",
    "    torch.tensor(test_data[LABEL_COL].values, dtype=torch.float32).to(device),\n",
    "    SEQUENCE_LENGTH,\n",
    "    test_data['SourceFile'].values,\n",
    "    test_data['Time [s]'].values  \n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)  \n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Print file names used in training, validation, and testing\n",
    "train_files = train_dataset.get_unique_filenames()\n",
    "val_files = val_dataset.get_unique_filenames()\n",
    "test_files = test_dataset.get_unique_filenames()\n",
    "\n",
    "train_files_sorted = sorted(train_files)\n",
    "val_files_sorted = sorted(val_files)\n",
    "test_files_sorted = sorted(test_files)\n",
    "\n",
    "print(\"Training files:\", train_files)\n",
    "print(\"\\nValidation files:\", val_files)\n",
    "print(\"\\nTesting files:\", test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b1a8cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: torch.Size([420861, 5])\n",
      "Test features shape: torch.Size([61263, 5])\n",
      "Train labels shape: torch.Size([420861])\n",
      "Test labels shape: torch.Size([61263])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train features shape:\", train_tensor.shape)\n",
    "print(\"Test features shape:\", test_tensor .shape)\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "print(\"Test labels shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0b5fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 11:28:36,232] A new study created in memory with name: no-name-53bbf3de-35d5-4d88-bb4b-d41990ebff96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.002181748628898801, Validation Loss: 2.6241700185838425e-05\n",
      "Time taken for epoch: 38.83314562 seconds\n",
      "Epoch 2/10, Train Loss: 3.209049079507628e-05, Validation Loss: 1.5855683356745332e-05\n",
      "Time taken for epoch: 39.20676970 seconds\n",
      "Epoch 3/10, Train Loss: 3.24181607232845e-05, Validation Loss: 3.953341003261986e-05\n",
      "Time taken for epoch: 40.20965314 seconds\n",
      "Epoch 4/10, Train Loss: 2.4503042915724633e-05, Validation Loss: 2.740366933625603e-05\n",
      "Time taken for epoch: 39.53385305 seconds\n",
      "Epoch 5/10, Train Loss: 1.994172907857131e-05, Validation Loss: 1.3666707649790853e-05\n",
      "Time taken for epoch: 38.85701156 seconds\n",
      "Epoch 6/10, Train Loss: 1.7953212227356524e-05, Validation Loss: 1.51868439945107e-05\n",
      "Time taken for epoch: 38.96214557 seconds\n",
      "Epoch 7/10, Train Loss: 1.854761634661609e-05, Validation Loss: 1.0251330749293836e-05\n",
      "Time taken for epoch: 38.68102241 seconds\n",
      "Epoch 8/10, Train Loss: 1.4211206433233832e-05, Validation Loss: 1.8074191558077235e-05\n",
      "Time taken for epoch: 39.31564808 seconds\n",
      "Epoch 9/10, Train Loss: 1.261821993659657e-05, Validation Loss: 1.5178437156201307e-05\n",
      "Time taken for epoch: 38.61854577 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 11:35:52,794] Trial 0 finished with value: 1.1132040123602718e-05 and parameters: {'hidden_size': 67, 'num_layers': 4, 'learning_rate': 0.01536023076194241}. Best is trial 0 with value: 1.1132040123602718e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 1.2615237243259054e-05, Validation Loss: 1.1132040123602718e-05\n",
      "Time taken for epoch: 38.91143632 seconds\n",
      "Epoch 1/10, Train Loss: 0.0009125531309153351, Validation Loss: 3.1682444231466803e-05\n",
      "Time taken for epoch: 38.12938643 seconds\n",
      "Epoch 2/10, Train Loss: 1.7131584069565403e-05, Validation Loss: 1.8451092882626588e-05\n",
      "Time taken for epoch: 37.89919257 seconds\n",
      "Epoch 3/10, Train Loss: 1.4299947950535712e-05, Validation Loss: 1.069612173667341e-05\n",
      "Time taken for epoch: 37.62581134 seconds\n",
      "Epoch 4/10, Train Loss: 1.254947393235941e-05, Validation Loss: 1.0748170470990832e-05\n",
      "Time taken for epoch: 38.07316422 seconds\n",
      "Epoch 5/10, Train Loss: 1.1212607275984536e-05, Validation Loss: 2.1065343589694496e-05\n",
      "Time taken for epoch: 37.26248693 seconds\n",
      "Epoch 6/10, Train Loss: 1.0823811832019457e-05, Validation Loss: 1.0759796463207952e-05\n",
      "Time taken for epoch: 37.37732553 seconds\n",
      "Epoch 7/10, Train Loss: 9.886450583103718e-06, Validation Loss: 1.2935505092857195e-05\n",
      "Time taken for epoch: 37.30898356 seconds\n",
      "Epoch 8/10, Train Loss: 9.547088797062692e-06, Validation Loss: 1.0756666988256664e-05\n",
      "Time taken for epoch: 37.41644526 seconds\n",
      "Epoch 9/10, Train Loss: 9.091245852137378e-06, Validation Loss: 2.1998593128838957e-05\n",
      "Time taken for epoch: 37.85495090 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 11:42:50,685] Trial 1 finished with value: 1.1440828566427236e-05 and parameters: {'hidden_size': 75, 'num_layers': 2, 'learning_rate': 0.0008345306374400352}. Best is trial 0 with value: 1.1132040123602718e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 8.513978666614162e-06, Validation Loss: 1.1440828566427236e-05\n",
      "Time taken for epoch: 37.59009767 seconds\n",
      "Epoch 1/10, Train Loss: 0.014590885438221688, Validation Loss: 0.0006755268290251071\n",
      "Time taken for epoch: 40.60005426 seconds\n",
      "Epoch 2/10, Train Loss: 0.00037556758067490735, Validation Loss: 0.0002739074983809902\n",
      "Time taken for epoch: 40.58807611 seconds\n",
      "Epoch 3/10, Train Loss: 0.00017765490593185676, Validation Loss: 0.00011702512409673025\n",
      "Time taken for epoch: 40.46676397 seconds\n",
      "Epoch 4/10, Train Loss: 7.293291726786035e-05, Validation Loss: 3.7676506963420316e-05\n",
      "Time taken for epoch: 40.36683464 seconds\n",
      "Epoch 5/10, Train Loss: 2.584809290067065e-05, Validation Loss: 1.6815901840409562e-05\n",
      "Time taken for epoch: 40.68486404 seconds\n",
      "Epoch 6/10, Train Loss: 1.529071866644055e-05, Validation Loss: 2.0842702466071082e-05\n",
      "Time taken for epoch: 40.20045114 seconds\n",
      "Epoch 7/10, Train Loss: 1.2680979727753485e-05, Validation Loss: 1.1283320808878583e-05\n",
      "Time taken for epoch: 40.43805051 seconds\n",
      "Epoch 8/10, Train Loss: 1.161681375630691e-05, Validation Loss: 1.1604437610526706e-05\n",
      "Time taken for epoch: 40.37746882 seconds\n",
      "Epoch 9/10, Train Loss: 1.0945846845402506e-05, Validation Loss: 1.1070385118999829e-05\n",
      "Time taken for epoch: 40.84966826 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 11:50:17,930] Trial 2 finished with value: 1.0647839426713764e-05 and parameters: {'hidden_size': 41, 'num_layers': 5, 'learning_rate': 8.747203416460033e-05}. Best is trial 2 with value: 1.0647839426713764e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 1.0694921257590823e-05, Validation Loss: 1.0647839426713764e-05\n",
      "Time taken for epoch: 40.60768342 seconds\n",
      "Epoch 1/10, Train Loss: 0.003175300092558675, Validation Loss: 0.00010405741797209098\n",
      "Time taken for epoch: 37.69007754 seconds\n",
      "Epoch 2/10, Train Loss: 3.9638552754790564e-05, Validation Loss: 2.340496755144497e-05\n",
      "Time taken for epoch: 37.44889855 seconds\n",
      "Epoch 3/10, Train Loss: 1.470626667801818e-05, Validation Loss: 1.605412130485056e-05\n",
      "Time taken for epoch: 37.43287730 seconds\n",
      "Epoch 4/10, Train Loss: 1.2370344388642223e-05, Validation Loss: 9.645330467304617e-06\n",
      "Time taken for epoch: 37.37604952 seconds\n",
      "Epoch 5/10, Train Loss: 1.1596240859603589e-05, Validation Loss: 9.290772458802939e-06\n",
      "Time taken for epoch: 36.97821236 seconds\n",
      "Epoch 6/10, Train Loss: 1.0716732450693329e-05, Validation Loss: 1.3239893744232175e-05\n",
      "Time taken for epoch: 37.79784942 seconds\n",
      "Epoch 7/10, Train Loss: 1.0250574410684436e-05, Validation Loss: 1.0319237244256117e-05\n",
      "Time taken for epoch: 37.65700698 seconds\n",
      "Epoch 8/10, Train Loss: 9.970560544346674e-06, Validation Loss: 1.0706634315036786e-05\n",
      "Time taken for epoch: 37.41847682 seconds\n",
      "Epoch 9/10, Train Loss: 9.576933422640804e-06, Validation Loss: 9.242658863019707e-06\n",
      "Time taken for epoch: 37.39789820 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 11:57:11,547] Trial 3 finished with value: 1.0842900502647075e-05 and parameters: {'hidden_size': 43, 'num_layers': 2, 'learning_rate': 0.00041747657899002033}. Best is trial 2 with value: 1.0647839426713764e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 9.400408764275646e-06, Validation Loss: 1.0842900502647075e-05\n",
      "Time taken for epoch: 37.34297371 seconds\n",
      "Epoch 1/10, Train Loss: 0.002278008235549647, Validation Loss: 5.413395337386101e-05\n",
      "Time taken for epoch: 38.05574894 seconds\n",
      "Epoch 2/10, Train Loss: 2.4126797154179606e-05, Validation Loss: 2.222491866882621e-05\n",
      "Time taken for epoch: 38.24045515 seconds\n",
      "Epoch 3/10, Train Loss: 1.5034166984512196e-05, Validation Loss: 1.5787621591632573e-05\n",
      "Time taken for epoch: 38.83593225 seconds\n",
      "Epoch 4/10, Train Loss: 1.2867409564084401e-05, Validation Loss: 2.3043868975977712e-05\n",
      "Time taken for epoch: 38.49248219 seconds\n",
      "Epoch 5/10, Train Loss: 1.1934774095279775e-05, Validation Loss: 1.0657987704224615e-05\n",
      "Time taken for epoch: 39.08523202 seconds\n",
      "Epoch 6/10, Train Loss: 1.1195428355499965e-05, Validation Loss: 1.1038963291311293e-05\n",
      "Time taken for epoch: 38.35312748 seconds\n",
      "Epoch 7/10, Train Loss: 1.060766924912422e-05, Validation Loss: 1.1807304339864834e-05\n",
      "Time taken for epoch: 38.11455727 seconds\n",
      "Epoch 8/10, Train Loss: 1.0248181782600133e-05, Validation Loss: 1.0165673791399846e-05\n",
      "Time taken for epoch: 38.48905301 seconds\n",
      "Epoch 9/10, Train Loss: 9.899377590132741e-06, Validation Loss: 1.5295466851777395e-05\n",
      "Time taken for epoch: 38.41323233 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 12:04:16,098] Trial 4 finished with value: 1.2647231084338157e-05 and parameters: {'hidden_size': 37, 'num_layers': 3, 'learning_rate': 0.000540772812354229}. Best is trial 2 with value: 1.0647839426713764e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 9.56352259319791e-06, Validation Loss: 1.2647231084338157e-05\n",
      "Time taken for epoch: 38.81864834 seconds\n",
      "Epoch 1/10, Train Loss: 0.00042709272516565876, Validation Loss: 2.9562354125747985e-05\n",
      "Time taken for epoch: 36.67337441 seconds\n",
      "Epoch 2/10, Train Loss: 1.8386915593296367e-05, Validation Loss: 2.7739261042353813e-05\n",
      "Time taken for epoch: 36.57531476 seconds\n",
      "Epoch 3/10, Train Loss: 1.7020580008308136e-05, Validation Loss: 1.0133446582403183e-05\n",
      "Time taken for epoch: 36.23163176 seconds\n",
      "Epoch 4/10, Train Loss: 1.4754843286140465e-05, Validation Loss: 2.512742037529927e-05\n",
      "Time taken for epoch: 36.08229613 seconds\n",
      "Epoch 5/10, Train Loss: 1.2777817151076098e-05, Validation Loss: 1.2830373759562937e-05\n",
      "Time taken for epoch: 36.27495217 seconds\n",
      "Epoch 6/10, Train Loss: 1.1884388933638596e-05, Validation Loss: 9.912717622875765e-06\n",
      "Time taken for epoch: 36.56924486 seconds\n",
      "Epoch 7/10, Train Loss: 1.0789503847292724e-05, Validation Loss: 1.1421875455455416e-05\n",
      "Time taken for epoch: 39.14738131 seconds\n",
      "Epoch 8/10, Train Loss: 1.0093401582817975e-05, Validation Loss: 1.2522021371735519e-05\n",
      "Time taken for epoch: 41.51445794 seconds\n",
      "Epoch 9/10, Train Loss: 9.5841319393951e-06, Validation Loss: 8.489697363470104e-06\n",
      "Time taken for epoch: 36.77594614 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 12:11:04,289] Trial 5 finished with value: 1.5984269866711244e-05 and parameters: {'hidden_size': 26, 'num_layers': 2, 'learning_rate': 0.005622556563494566}. Best is trial 2 with value: 1.0647839426713764e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 9.070889906018077e-06, Validation Loss: 1.5984269866711244e-05\n",
      "Time taken for epoch: 36.03767633 seconds\n",
      "Epoch 1/10, Train Loss: 0.0004803449133813405, Validation Loss: 2.4699772959923866e-05\n",
      "Time taken for epoch: 38.70780158 seconds\n",
      "Epoch 2/10, Train Loss: 4.9223384807260505e-05, Validation Loss: 4.014615358634826e-05\n",
      "Time taken for epoch: 41.04274702 seconds\n",
      "Epoch 3/10, Train Loss: 3.0917415938872966e-05, Validation Loss: 3.402556040502499e-05\n",
      "Time taken for epoch: 40.59783292 seconds\n",
      "Epoch 4/10, Train Loss: 2.7321335919861265e-05, Validation Loss: 1.504423873716643e-05\n",
      "Time taken for epoch: 40.40264249 seconds\n",
      "Epoch 5/10, Train Loss: 1.8060044053726395e-05, Validation Loss: 9.448102887845972e-06\n",
      "Time taken for epoch: 40.71051002 seconds\n",
      "Epoch 6/10, Train Loss: 1.6116213556792204e-05, Validation Loss: 1.1457573436348723e-05\n",
      "Time taken for epoch: 40.64481378 seconds\n",
      "Epoch 7/10, Train Loss: 1.4137100118248277e-05, Validation Loss: 1.6951027377661106e-05\n",
      "Time taken for epoch: 40.41138554 seconds\n",
      "Epoch 8/10, Train Loss: 0.0003412306698159163, Validation Loss: 5.467893183408003e-05\n",
      "Time taken for epoch: 40.63164401 seconds\n",
      "Epoch 9/10, Train Loss: 3.518718079502459e-05, Validation Loss: 4.134874985772128e-05\n",
      "Time taken for epoch: 47.97173810 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 12:18:42,191] Trial 6 finished with value: 2.220175107004803e-05 and parameters: {'hidden_size': 54, 'num_layers': 2, 'learning_rate': 0.03220113922466007}. Best is trial 2 with value: 1.0647839426713764e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 2.6748886304399767e-05, Validation Loss: 2.220175107004803e-05\n",
      "Time taken for epoch: 46.90990639 seconds\n",
      "Epoch 1/10, Train Loss: 0.0005168025132097837, Validation Loss: 1.1162802114008935e-05\n",
      "Time taken for epoch: 44.94535494 seconds\n",
      "Epoch 2/10, Train Loss: 2.4809419521483984e-05, Validation Loss: 3.192047838180743e-05\n",
      "Time taken for epoch: 46.29263496 seconds\n",
      "Epoch 3/10, Train Loss: 2.3647136280749983e-05, Validation Loss: 3.939395195654855e-05\n",
      "Time taken for epoch: 50.71014309 seconds\n",
      "Epoch 4/10, Train Loss: 1.8418332889354942e-05, Validation Loss: 1.0939716286238998e-05\n",
      "Time taken for epoch: 45.58876681 seconds\n",
      "Epoch 5/10, Train Loss: 1.7291913817092936e-05, Validation Loss: 1.6394359784200238e-05\n",
      "Time taken for epoch: 46.19642448 seconds\n",
      "Epoch 6/10, Train Loss: 1.5364581463389875e-05, Validation Loss: 1.64153782655955e-05\n",
      "Time taken for epoch: 45.59737515 seconds\n",
      "Epoch 7/10, Train Loss: 1.3929567002922832e-05, Validation Loss: 1.642202881242983e-05\n",
      "Time taken for epoch: 48.98230267 seconds\n",
      "Epoch 8/10, Train Loss: 1.4386148363567631e-05, Validation Loss: 4.231165728069708e-05\n",
      "Time taken for epoch: 47.47427630 seconds\n",
      "Epoch 9/10, Train Loss: 1.2932228930888407e-05, Validation Loss: 1.103356115240275e-05\n",
      "Time taken for epoch: 45.95693851 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 12:27:17,325] Trial 7 finished with value: 1.5729575134069094e-05 and parameters: {'hidden_size': 35, 'num_layers': 1, 'learning_rate': 0.02136806560277504}. Best is trial 2 with value: 1.0647839426713764e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 1.2299159779261343e-05, Validation Loss: 1.5729575134069094e-05\n",
      "Time taken for epoch: 46.61295390 seconds\n",
      "Epoch 1/10, Train Loss: 0.0021225352073012496, Validation Loss: 6.340023127837431e-05\n",
      "Time taken for epoch: 51.59769201 seconds\n",
      "Epoch 2/10, Train Loss: 2.3065559426091555e-05, Validation Loss: 1.7566839425433397e-05\n",
      "Time taken for epoch: 51.20828342 seconds\n",
      "Epoch 3/10, Train Loss: 1.6616618212418518e-05, Validation Loss: 1.848329070191263e-05\n",
      "Time taken for epoch: 51.41674185 seconds\n",
      "Epoch 4/10, Train Loss: 1.3833482702413316e-05, Validation Loss: 1.2518396525607045e-05\n",
      "Time taken for epoch: 54.39400864 seconds\n",
      "Epoch 5/10, Train Loss: 1.2650582678537312e-05, Validation Loss: 1.2223156157943133e-05\n",
      "Time taken for epoch: 51.60068154 seconds\n",
      "Epoch 6/10, Train Loss: 1.163507879595905e-05, Validation Loss: 1.3594842694624958e-05\n",
      "Time taken for epoch: 51.43241382 seconds\n",
      "Epoch 7/10, Train Loss: 1.0876346802633812e-05, Validation Loss: 1.1463833350146931e-05\n",
      "Time taken for epoch: 53.69621372 seconds\n",
      "Epoch 8/10, Train Loss: 1.0330508310136346e-05, Validation Loss: 1.4420476753441962e-05\n",
      "Time taken for epoch: 51.34749722 seconds\n",
      "Epoch 9/10, Train Loss: 9.453847977315191e-06, Validation Loss: 1.0399227379456472e-05\n",
      "Time taken for epoch: 49.54942298 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 12:36:36,227] Trial 8 finished with value: 1.6388179656298742e-05 and parameters: {'hidden_size': 70, 'num_layers': 4, 'learning_rate': 0.0004959890764784705}. Best is trial 2 with value: 1.0647839426713764e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 8.940196619043022e-06, Validation Loss: 1.6388179656298742e-05\n",
      "Time taken for epoch: 42.86067533 seconds\n",
      "Epoch 1/10, Train Loss: 0.006911267238481779, Validation Loss: 0.00018398703681066334\n",
      "Time taken for epoch: 39.88009024 seconds\n",
      "Epoch 2/10, Train Loss: 7.950386316915993e-05, Validation Loss: 3.65337739580605e-05\n",
      "Time taken for epoch: 39.49731207 seconds\n",
      "Epoch 3/10, Train Loss: 2.0107142632893143e-05, Validation Loss: 1.4983307292541912e-05\n",
      "Time taken for epoch: 40.35275769 seconds\n",
      "Epoch 4/10, Train Loss: 1.2978576465693306e-05, Validation Loss: 1.015501322054746e-05\n",
      "Time taken for epoch: 39.88385057 seconds\n",
      "Epoch 5/10, Train Loss: 1.1431902614587534e-05, Validation Loss: 1.0951690330994722e-05\n",
      "Time taken for epoch: 39.63033462 seconds\n",
      "Epoch 6/10, Train Loss: 1.07706826891803e-05, Validation Loss: 1.096681490218882e-05\n",
      "Time taken for epoch: 41.33282137 seconds\n",
      "Epoch 7/10, Train Loss: 1.0238696151525253e-05, Validation Loss: 1.1672315627257877e-05\n",
      "Time taken for epoch: 41.79447985 seconds\n",
      "Epoch 8/10, Train Loss: 9.705844206841117e-06, Validation Loss: 9.151393534242368e-06\n",
      "Time taken for epoch: 41.06696868 seconds\n",
      "Epoch 9/10, Train Loss: 9.178860647335699e-06, Validation Loss: 1.1240495902527322e-05\n",
      "Time taken for epoch: 41.21288323 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 12:44:02,462] Trial 9 finished with value: 1.3743975382628708e-05 and parameters: {'hidden_size': 32, 'num_layers': 3, 'learning_rate': 0.0002534383221159352}. Best is trial 2 with value: 1.0647839426713764e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 9.104310056912402e-06, Validation Loss: 1.3743975382628708e-05\n",
      "Time taken for epoch: 43.06514525 seconds\n",
      "Best trial: FrozenTrial(number=2, state=1, values=[1.0647839426713764e-05], datetime_start=datetime.datetime(2025, 8, 16, 11, 42, 50, 685294), datetime_complete=datetime.datetime(2025, 8, 16, 11, 50, 17, 930520), params={'hidden_size': 41, 'num_layers': 5, 'learning_rate': 8.747203416460033e-05}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'hidden_size': IntDistribution(high=100, log=False, low=10, step=1), 'num_layers': IntDistribution(high=5, log=False, low=1, step=1), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None)}, trial_id=2, value=None)\n",
      "Best hyperparameters: {'hidden_size': 41, 'num_layers': 5, 'learning_rate': 8.747203416460033e-05}\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\vinay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\visualization\\_plotly_imports.py:7\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m try_import() \u001b[38;5;28;01mas\u001b[39;00m _imports:\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m plotly_version\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_optimization_history, plot_param_importances\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Plot optimization history\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m optimization_history \u001b[38;5;241m=\u001b[39m \u001b[43mplot_optimization_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m optimization_history\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Plot hyperparameter importance\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vinay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\visualization\\_optimization_history.py:200\u001b[0m, in \u001b[0;36mplot_optimization_history\u001b[1;34m(study, target, target_name, error_bar)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_optimization_history\u001b[39m(\n\u001b[0;32m    173\u001b[0m     study: Study \u001b[38;5;241m|\u001b[39m Sequence[Study],\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m     error_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    178\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgo.Figure\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Plot optimization history of all trials in a study.\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \n\u001b[0;32m    181\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m        A :class:`plotly.graph_objects.Figure` object.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m     \u001b[43m_imports\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m     info_list \u001b[38;5;241m=\u001b[39m _get_optimization_history_info_list(study, target, target_name, error_bar)\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_optimization_history_plot(info_list, target_name)\n",
      "File \u001b[1;32mc:\\Users\\vinay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\_imports.py:94\u001b[0m, in \u001b[0;36m_DeferredImportExceptionContextManager.check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deferred \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     exc_value, message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deferred\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc_value\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'."
     ]
    }
   ],
   "source": [
    "if not skip_optuna:\n",
    "    # Define Optuna objective function\n",
    "    def objective(trial):\n",
    "        # Suggest hyperparameters\n",
    "        hidden_size = trial.suggest_int('hidden_size', 10, 100)\n",
    "        num_layers = trial.suggest_int('num_layers', 1, 5)\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "\n",
    "        # Instantiate model with suggested hyperparameters\n",
    "        model = SoCLSTM(input_size=len(FEATURE_COLS), hidden_size=hidden_size, num_layers=num_layers).type(torch.float32).to(device)\n",
    "\n",
    "        # Define your loss function and optimizer with suggested hyperparameters\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Call your train and validate function\n",
    "        history = train_and_validate(model, criterion, optimizer, train_loader, val_loader, EPOCHS, device)\n",
    "\n",
    "        # Extract last validation loss\n",
    "        last_val_loss = history['val_loss'][-1]\n",
    "        return last_val_loss\n",
    "\n",
    "    # Optuna study\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=10)\n",
    "\n",
    "    # Extract best trial\n",
    "    best_trial = study.best_trial\n",
    "    print(f\"Best trial: {best_trial}\")\n",
    "\n",
    "    best_hyperparams = study.best_trial.params\n",
    "    print('Best hyperparameters:', best_hyperparams)\n",
    "\n",
    "    # Visualize the optimization process\n",
    "    from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "\n",
    "    # Plot optimization history\n",
    "    optimization_history = plot_optimization_history(study)\n",
    "    optimization_history.show()\n",
    "\n",
    "    # Plot hyperparameter importance\n",
    "    param_importances = plot_param_importances(study)\n",
    "    param_importances.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc29c81",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optuna' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Optuna study\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[43moptuna\u001b[49m\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Extract best trial\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optuna' is not defined"
     ]
    }
   ],
   "source": [
    "    # Optuna study\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "    # Extract best trial\n",
    "best_trial = study.best_trial\n",
    "print(f\"Best trial: {best_trial}\")\n",
    "\n",
    "best_hyperparams = study.best_trial.params\n",
    "print('Best hyperparameters:', best_hyperparams)\n",
    "\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "\n",
    "# Plot optimization history\n",
    "optimization_history = plot_optimization_history(study)\n",
    "optimization_history.show()\n",
    "\n",
    "# Plot hyperparameter importance\n",
    "param_importances = plot_param_importances(study)\n",
    "param_importances.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5296d1d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SoCLSTM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m     10\u001b[0m LEARNING_RATE \u001b[38;5;241m=\u001b[39m best_hyperparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSoCLSTM\u001b[49m(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(FEATURE_COLS), hidden_size\u001b[38;5;241m=\u001b[39mhidden_size, num_layers\u001b[38;5;241m=\u001b[39mnum_layers)\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     14\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLEARNING_RATE)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SoCLSTM' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "skip_training = os.getenv('SKIP_TRAINING', 'False') == 'True'\n",
    "if not skip_training:\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    best_hyperparams = {'hidden_size': 94, 'num_layers': 4, 'learning_rate': 3.5218624376812995e-05}\n",
    "    hidden_size = best_hyperparams['hidden_size']\n",
    "    num_layers = best_hyperparams['num_layers']\n",
    "    \n",
    "    EPOCHS = 20\n",
    "    LEARNING_RATE = best_hyperparams['learning_rate']\n",
    "\n",
    "    model = SoCLSTM(input_size=len(FEATURE_COLS), hidden_size=hidden_size, num_layers=num_layers)\n",
    "    model.to(device).type(torch.float32)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Train and validate the model\n",
    "    history = train_and_validate(model, criterion, optimizer, train_loader, val_loader, EPOCHS, device)\n",
    "\n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Save the model\n",
    "    model_path = \"soc_lstm_model.pth\"\n",
    "    torch.save({'model_state_dict': model.state_dict(), 'input_size': len(FEATURE_COLS)}, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
